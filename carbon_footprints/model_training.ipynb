{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebdf918d-7080-48df-b9e1-9a6548b8c549",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adity\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - loss: 6112080.0000 - mae: 2259.9006 - val_loss: 6258333.0000 - val_mae: 2292.3770\n",
      "Epoch 2/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 6071734.0000 - mae: 2255.5396 - val_loss: 6160207.0000 - val_mae: 2281.6997\n",
      "Epoch 3/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5969579.0000 - mae: 2245.4397 - val_loss: 6012963.0000 - val_mae: 2262.1357\n",
      "Epoch 4/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5786353.0000 - mae: 2211.3323 - val_loss: 5787802.5000 - val_mae: 2229.8147\n",
      "Epoch 5/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5586552.5000 - mae: 2183.7188 - val_loss: 5541905.0000 - val_mae: 2190.9299\n",
      "Epoch 6/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5279488.0000 - mae: 2137.5786 - val_loss: 5235928.5000 - val_mae: 2140.9390\n",
      "Epoch 7/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5058031.0000 - mae: 2097.6484 - val_loss: 4943525.5000 - val_mae: 2092.7305\n",
      "Epoch 8/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4769759.0000 - mae: 2046.3175 - val_loss: 4577103.0000 - val_mae: 2022.4420\n",
      "Epoch 9/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4404522.0000 - mae: 1979.4596 - val_loss: 4322084.0000 - val_mae: 1977.4336\n",
      "Epoch 10/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4062731.0000 - mae: 1910.8491 - val_loss: 3927217.0000 - val_mae: 1899.9338\n",
      "Epoch 11/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3876059.7500 - mae: 1872.7529 - val_loss: 3545037.5000 - val_mae: 1814.9393\n",
      "Epoch 12/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3506178.5000 - mae: 1791.8871 - val_loss: 3255549.2500 - val_mae: 1746.7343\n",
      "Epoch 13/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3229771.5000 - mae: 1730.0553 - val_loss: 2859256.2500 - val_mae: 1648.6625\n",
      "Epoch 14/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2914987.7500 - mae: 1650.1921 - val_loss: 2587343.2500 - val_mae: 1578.3728\n",
      "Epoch 15/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2671351.0000 - mae: 1579.9709 - val_loss: 2323422.2500 - val_mae: 1504.9318\n",
      "Epoch 16/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2316657.7500 - mae: 1474.9738 - val_loss: 2058722.1250 - val_mae: 1423.7198\n",
      "Epoch 17/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2114962.0000 - mae: 1411.2325 - val_loss: 1834546.5000 - val_mae: 1344.3223\n",
      "Epoch 18/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1834904.8750 - mae: 1314.6321 - val_loss: 1590387.7500 - val_mae: 1252.9492\n",
      "Epoch 19/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1680483.2500 - mae: 1255.6768 - val_loss: 1284708.2500 - val_mae: 1126.9615\n",
      "Epoch 20/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1410430.1250 - mae: 1146.4009 - val_loss: 1127772.0000 - val_mae: 1055.5607\n",
      "Epoch 21/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1202910.6250 - mae: 1047.5074 - val_loss: 881168.2500 - val_mae: 930.8959\n",
      "Epoch 22/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1106866.5000 - mae: 997.2532 - val_loss: 739930.2500 - val_mae: 850.4969\n",
      "Epoch 23/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 872657.5625 - mae: 881.2488 - val_loss: 664166.5000 - val_mae: 806.8964\n",
      "Epoch 24/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 760882.3125 - mae: 812.1898 - val_loss: 510138.8125 - val_mae: 705.0109\n",
      "Epoch 25/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 599525.6875 - mae: 706.8807 - val_loss: 404897.0938 - val_mae: 622.1863\n",
      "Epoch 26/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 512608.2812 - mae: 645.7674 - val_loss: 340242.4688 - val_mae: 572.7299\n",
      "Epoch 27/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 454645.1875 - mae: 594.6489 - val_loss: 251855.8438 - val_mae: 486.9034\n",
      "Epoch 28/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 345718.6562 - mae: 505.2953 - val_loss: 188553.9531 - val_mae: 415.8430\n",
      "Epoch 29/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 254860.8906 - mae: 427.0275 - val_loss: 147302.3125 - val_mae: 366.4708\n",
      "Epoch 30/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 215259.0000 - mae: 373.5527 - val_loss: 83422.0000 - val_mae: 263.6335\n",
      "Epoch 31/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 197389.0625 - mae: 348.3873 - val_loss: 65325.1094 - val_mae: 232.3805\n",
      "Epoch 32/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 158916.6562 - mae: 310.4165 - val_loss: 45804.2617 - val_mae: 179.4872\n",
      "Epoch 33/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 141454.1094 - mae: 289.4785 - val_loss: 40991.2695 - val_mae: 160.6928\n",
      "Epoch 34/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 134963.1562 - mae: 274.8267 - val_loss: 24811.9492 - val_mae: 112.2273\n",
      "Epoch 35/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 123154.9531 - mae: 267.1104 - val_loss: 22044.6074 - val_mae: 115.9932\n",
      "Epoch 36/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 132295.0000 - mae: 275.6702 - val_loss: 17912.5391 - val_mae: 92.2810\n",
      "Epoch 37/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 132646.9688 - mae: 270.0977 - val_loss: 20020.1992 - val_mae: 91.4221\n",
      "Epoch 38/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 120730.8359 - mae: 261.8068 - val_loss: 16091.8301 - val_mae: 90.4459\n",
      "Epoch 39/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 116640.9531 - mae: 260.5074 - val_loss: 16573.6055 - val_mae: 86.6838\n",
      "Epoch 40/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 136700.0625 - mae: 278.3265 - val_loss: 12490.9951 - val_mae: 81.5095\n",
      "Epoch 41/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 123472.2266 - mae: 264.2136 - val_loss: 14095.9209 - val_mae: 85.1319\n",
      "Epoch 42/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 115821.3672 - mae: 256.1884 - val_loss: 12671.9277 - val_mae: 81.6488\n",
      "Epoch 43/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 115770.9219 - mae: 257.7078 - val_loss: 15265.6748 - val_mae: 90.8312\n",
      "Epoch 44/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 109294.6953 - mae: 251.1957 - val_loss: 14045.0498 - val_mae: 84.5043\n",
      "Epoch 45/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 108675.6328 - mae: 252.5377 - val_loss: 17464.2949 - val_mae: 95.7019\n",
      "Epoch 46/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 120770.2031 - mae: 262.7601 - val_loss: 15210.5889 - val_mae: 92.2853\n",
      "Epoch 47/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 129171.9453 - mae: 272.1680 - val_loss: 12807.4570 - val_mae: 82.0943\n",
      "Epoch 48/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 109515.5469 - mae: 250.6382 - val_loss: 14294.5889 - val_mae: 87.0061\n",
      "Epoch 49/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 110849.0547 - mae: 251.6244 - val_loss: 15126.5576 - val_mae: 90.5533\n",
      "Epoch 50/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 125201.6719 - mae: 267.5838 - val_loss: 11788.4189 - val_mae: 79.4944\n",
      "Epoch 51/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 108993.5312 - mae: 251.9376 - val_loss: 13625.4561 - val_mae: 83.3734\n",
      "Epoch 52/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 110535.3516 - mae: 250.4213 - val_loss: 14460.1396 - val_mae: 87.1963\n",
      "Epoch 53/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 104097.3516 - mae: 248.2998 - val_loss: 16445.7285 - val_mae: 97.4594\n",
      "Epoch 54/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 108442.8203 - mae: 251.7696 - val_loss: 14917.3340 - val_mae: 89.9404\n",
      "Epoch 55/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 106172.6719 - mae: 247.7975 - val_loss: 13371.8916 - val_mae: 81.1231\n",
      "Epoch 56/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 105220.3594 - mae: 243.2258 - val_loss: 13982.6934 - val_mae: 84.0922\n",
      "Epoch 57/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 107169.3438 - mae: 247.1466 - val_loss: 18015.2949 - val_mae: 98.6463\n",
      "Epoch 58/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 102651.6562 - mae: 245.9803 - val_loss: 16906.7637 - val_mae: 85.4642\n",
      "Epoch 59/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 105233.0547 - mae: 245.0720 - val_loss: 13220.8086 - val_mae: 81.7693\n",
      "Epoch 60/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 117415.6094 - mae: 258.7814 - val_loss: 15770.0234 - val_mae: 89.7949\n",
      "Epoch 61/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 122371.5000 - mae: 262.5354 - val_loss: 14516.8828 - val_mae: 85.6197\n",
      "Epoch 62/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 109414.9688 - mae: 249.4741 - val_loss: 20164.9648 - val_mae: 104.9170\n",
      "Epoch 63/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 107350.4297 - mae: 251.0435 - val_loss: 17346.2520 - val_mae: 93.7090\n",
      "Epoch 64/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 115119.7188 - mae: 257.3006 - val_loss: 12884.4492 - val_mae: 82.4327\n",
      "Epoch 65/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 108324.2266 - mae: 250.5176 - val_loss: 13997.5166 - val_mae: 85.4741\n",
      "Epoch 66/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 114341.2969 - mae: 257.5101 - val_loss: 17303.9473 - val_mae: 97.8874\n",
      "Epoch 67/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 115804.5859 - mae: 257.8984 - val_loss: 18086.1973 - val_mae: 96.3266\n",
      "Epoch 68/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 111797.9922 - mae: 254.4225 - val_loss: 13465.6084 - val_mae: 85.1492\n",
      "Epoch 69/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 108392.2500 - mae: 252.3004 - val_loss: 18287.5977 - val_mae: 94.9918\n",
      "Epoch 70/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 109404.9297 - mae: 249.7043 - val_loss: 11978.8223 - val_mae: 80.2185\n",
      "Epoch 71/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 108450.1641 - mae: 248.6327 - val_loss: 15954.8779 - val_mae: 92.0219\n",
      "Epoch 72/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 104296.4297 - mae: 247.2489 - val_loss: 14933.7383 - val_mae: 87.6651\n",
      "Epoch 73/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 110250.6094 - mae: 248.3437 - val_loss: 14349.8984 - val_mae: 85.4410\n",
      "Epoch 74/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 109800.5859 - mae: 248.9315 - val_loss: 15010.2930 - val_mae: 87.9433\n",
      "Epoch 75/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 100976.1641 - mae: 245.5810 - val_loss: 15831.6572 - val_mae: 91.2422\n",
      "Epoch 76/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 107321.1328 - mae: 252.3785 - val_loss: 18870.4609 - val_mae: 102.7875\n",
      "Epoch 77/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 99283.7891 - mae: 240.5775 - val_loss: 15297.9766 - val_mae: 88.3035\n",
      "Epoch 78/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 112401.9375 - mae: 256.2597 - val_loss: 15110.9580 - val_mae: 92.0545\n",
      "Epoch 79/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 112711.3359 - mae: 255.8749 - val_loss: 15148.8477 - val_mae: 90.5710\n",
      "Epoch 80/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 104191.3672 - mae: 247.0452 - val_loss: 14233.2910 - val_mae: 86.3073\n",
      "Epoch 81/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 105829.2031 - mae: 248.4518 - val_loss: 13212.0996 - val_mae: 82.4805\n",
      "Epoch 82/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 104062.8672 - mae: 245.9525 - val_loss: 14397.9482 - val_mae: 87.7977\n",
      "Epoch 83/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 102179.1875 - mae: 241.0043 - val_loss: 16211.9336 - val_mae: 91.4488\n",
      "Epoch 84/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 104873.1016 - mae: 243.7620 - val_loss: 12503.5947 - val_mae: 80.4611\n",
      "Epoch 85/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 118556.4688 - mae: 262.1696 - val_loss: 12666.0293 - val_mae: 80.7415\n",
      "Epoch 86/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 106381.0078 - mae: 249.9933 - val_loss: 16455.7656 - val_mae: 93.5791\n",
      "Epoch 87/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 108668.6250 - mae: 249.8561 - val_loss: 15107.5820 - val_mae: 87.5558\n",
      "Epoch 88/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 125288.6641 - mae: 267.1910 - val_loss: 15240.7109 - val_mae: 85.6096\n",
      "Epoch 89/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 103132.5703 - mae: 245.4005 - val_loss: 15199.7578 - val_mae: 91.2122\n",
      "Epoch 90/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 116491.8125 - mae: 258.8836 - val_loss: 16519.7109 - val_mae: 88.6435\n",
      "Epoch 91/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 110884.5781 - mae: 257.1713 - val_loss: 16209.0156 - val_mae: 84.9579\n",
      "Epoch 92/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 119658.2969 - mae: 256.8799 - val_loss: 15329.2900 - val_mae: 88.3248\n",
      "Epoch 93/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 103744.2734 - mae: 245.9285 - val_loss: 17405.5820 - val_mae: 95.9973\n",
      "Epoch 94/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 108140.9844 - mae: 248.9281 - val_loss: 15177.2393 - val_mae: 88.3264\n",
      "Epoch 95/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 112028.0547 - mae: 254.1111 - val_loss: 15749.1660 - val_mae: 92.0602\n",
      "Epoch 96/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 111687.8203 - mae: 253.2345 - val_loss: 15365.4131 - val_mae: 88.1257\n",
      "Epoch 97/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 111673.3906 - mae: 257.3487 - val_loss: 19660.3984 - val_mae: 99.9971\n",
      "Epoch 98/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 111149.4141 - mae: 252.6406 - val_loss: 15075.2559 - val_mae: 86.6046\n",
      "Epoch 99/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 112825.9688 - mae: 253.9084 - val_loss: 17411.9375 - val_mae: 95.3672\n",
      "Epoch 100/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 111141.3516 - mae: 251.7967 - val_loss: 14910.2744 - val_mae: 82.0873\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "Neural Network Performance:\n",
      "MAE: 82.09\n",
      "RMSE: 122.11\n",
      "R² Score: 0.99\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv(\"C:/Users/adity/Downloads/Carbon Emission.csv/Carbon Emission.csv\")\n",
    "\n",
    "# Drop rows with missing target values\n",
    "data = data.dropna(subset=[\"CarbonEmission\"])\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data.drop(columns=[\"CarbonEmission\"])\n",
    "y = data[\"CarbonEmission\"]\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_cols = X.select_dtypes(include=[\"object\"]).columns\n",
    "numerical_cols = X.select_dtypes(exclude=[\"object\"]).columns\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "X_encoded = pd.DataFrame(encoder.fit_transform(X[categorical_cols]))\n",
    "\n",
    "# Preserve column names\n",
    "X_encoded.columns = encoder.get_feature_names_out(categorical_cols)\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X[numerical_cols]), columns=numerical_cols)\n",
    "\n",
    "# Combine processed categorical and numerical data\n",
    "X_final = pd.concat([X_scaled, X_encoded], axis=1)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_final, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build Neural Network Model\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),  # Input Layer\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    Dense(64, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    Dense(32, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    Dense(1, activation='linear')  # Output layer for regression\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
    "\n",
    "# Train model\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=32, verbose=1)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Neural Network Performance:\\nMAE: {mae:.2f}\\nRMSE: {rmse:.2f}\\nR² Score: {r2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "37bc63cf-827a-4a50-a793-53e0a0da97dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your body type (e.g., overweight, obese, normal):  normal\n",
      "Enter your sex (male/female):  male\n",
      "Enter your diet (e.g., omnivore, vegetarian, vegan):  omnivore\n",
      "How often do you shower (e.g., daily, less frequently):  daily\n",
      "Enter heating energy source (e.g., natural gas, coal, wood):  wood\n",
      "Enter transport type (e.g., public, private, walk/bicycle):  private\n",
      "Enter vehicle type (if applicable, e.g., petrol, diesel, electric):  petrol\n",
      "How often do you socialize (e.g., often, rarely, never):  often\n",
      "Enter your monthly grocery bill:  5000\n",
      "How often do you travel by air (e.g., frequently, rarely, never):  rarely\n",
      "Enter vehicle monthly distance in km:  400\n",
      "Enter waste bag size (e.g., small, large, extra large):  large\n",
      "Enter waste bag weekly count:  4\n",
      "How long do you use TV/PC daily (hours):  4\n",
      "How many new clothes do you buy monthly:  4\n",
      "How long do you use the internet daily (hours):  5\n",
      "Do you use energy-efficient appliances? (Yes/No):  yes\n",
      "Enter the materials you recycle (e.g., ['Metal', 'Plastic']):  metal\n",
      "Enter cooking appliances used (e.g., ['Stove', 'Microwave']):  stove\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\n",
      "🌍 **Carbon Footprint Report** 🌍\n",
      "📊 **Total Carbon Emission**: 4153.50 kg CO₂ per month\n",
      "\n",
      "📌 **Breakdown by Category:**\n",
      "  - Transport: 80.00 kg CO₂\n",
      "  - Energy: 150.00 kg CO₂\n",
      "  - Food: 200.00 kg CO₂\n",
      "  - Shopping: 200.00 kg CO₂\n",
      "  - Waste: 40.00 kg CO₂\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ **AI-Powered Reduction Strategies**\n",
      "➡️ Reduce meat consumption and opt for plant-based meals.\n",
      "➡️ Buy sustainable products and reduce unnecessary purchases.\n"
     ]
    }
   ],
   "source": [
    "# Function to take user input and predict carbon footprint\n",
    "def generate_carbon_report():\n",
    "    user_input = {\n",
    "        \"Body Type\": input(\"Enter your body type (e.g., overweight, obese, normal): \"),\n",
    "        \"Sex\": input(\"Enter your sex (male/female): \"),\n",
    "        \"Diet\": input(\"Enter your diet (e.g., omnivore, vegetarian, vegan): \"),\n",
    "        \"How Often Shower\": input(\"How often do you shower (e.g., daily, less frequently): \"),\n",
    "        \"Heating Energy Source\": input(\"Enter heating energy source (e.g., natural gas, coal, wood): \"),\n",
    "        \"Transport\": input(\"Enter transport type (e.g., public, private, walk/bicycle): \"),\n",
    "        \"Vehicle Type\": input(\"Enter vehicle type (if applicable, e.g., petrol, diesel, electric): \"),\n",
    "        \"Social Activity\": input(\"How often do you socialize (e.g., often, rarely, never): \"),\n",
    "        \"Monthly Grocery Bill\": float(input(\"Enter your monthly grocery bill: \")),\n",
    "        \"Frequency of Traveling by Air\": input(\"How often do you travel by air (e.g., frequently, rarely, never): \"),\n",
    "        \"Vehicle Monthly Distance Km\": float(input(\"Enter vehicle monthly distance in km: \")),\n",
    "        \"Waste Bag Size\": input(\"Enter waste bag size (e.g., small, large, extra large): \"),\n",
    "        \"Waste Bag Weekly Count\": int(input(\"Enter waste bag weekly count: \")),\n",
    "        \"How Long TV PC Daily Hour\": int(input(\"How long do you use TV/PC daily (hours): \")),\n",
    "        \"How Many New Clothes Monthly\": int(input(\"How many new clothes do you buy monthly: \")),\n",
    "        \"How Long Internet Daily Hour\": int(input(\"How long do you use the internet daily (hours): \")),\n",
    "        \"Energy efficiency\": input(\"Do you use energy-efficient appliances? (Yes/No): \"),\n",
    "        \"Recycling\": input(\"Enter the materials you recycle (e.g., ['Metal', 'Plastic']): \"),\n",
    "        \"Cooking_With\": input(\"Enter cooking appliances used (e.g., ['Stove', 'Microwave']): \")\n",
    "    }\n",
    "\n",
    "    # Convert user input to DataFrame\n",
    "    user_df = pd.DataFrame([user_input])\n",
    "\n",
    "    # Apply the same encoding and scaling used during training\n",
    "    user_encoded = pd.DataFrame(encoder.transform(user_df[categorical_cols]))\n",
    "    user_encoded.columns = encoder.get_feature_names_out(categorical_cols)\n",
    "\n",
    "    user_scaled = pd.DataFrame(scaler.transform(user_df[numerical_cols]), columns=numerical_cols)\n",
    "\n",
    "    user_final = pd.concat([user_scaled, user_encoded], axis=1)\n",
    "\n",
    "    # Predict carbon footprint\n",
    "    carbon_emission = model.predict(user_final)[0][0]\n",
    "\n",
    "    # Define category-wise emission factors (These should be tuned based on actual dataset insights)\n",
    "    transport_emission = user_df[\"Vehicle Monthly Distance Km\"].values[0] * 0.2  # Assuming 0.2 kg CO₂ per km\n",
    "    energy_emission = 300 if user_df[\"Heating Energy Source\"].values[0] in [\"coal\", \"natural gas\"] else 150  # Approximate values\n",
    "    food_emission = 200 if user_df[\"Diet\"].values[0] == \"omnivore\" else 100  # Plant-based diets have lower emissions\n",
    "    shopping_emission = user_df[\"How Many New Clothes Monthly\"].values[0] * 50  # Each new clothing item ~50kg CO₂\n",
    "    waste_emission = user_df[\"Waste Bag Weekly Count\"].values[0] * 10  # Approximate per bag emissions\n",
    "\n",
    "    # Carbon footprint breakdown\n",
    "    carbon_breakdown = {\n",
    "        \"transport\": transport_emission,\n",
    "        \"energy\": energy_emission,\n",
    "        \"food\": food_emission,\n",
    "        \"shopping\": shopping_emission,\n",
    "        \"waste\": waste_emission\n",
    "    }\n",
    "\n",
    "    # AI-powered reduction tips\n",
    "    reduction_tips = {\n",
    "        \"transport\": \"Use public transport or carpool to reduce emissions.\",\n",
    "        \"energy\": \"Switch to renewable energy sources to lower footprint.\",\n",
    "        \"food\": \"Reduce meat consumption and opt for plant-based meals.\",\n",
    "        \"shopping\": \"Buy sustainable products and reduce unnecessary purchases.\",\n",
    "        \"waste\": \"Recycle and compost to minimize waste emissions.\"\n",
    "    }\n",
    "\n",
    "    # Sort and select top 2 highest emissions sources\n",
    "    sorted_categories = sorted(carbon_breakdown.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Print Carbon Footprint Report\n",
    "    print(\"\\n🌍 **Carbon Footprint Report** 🌍\")\n",
    "    print(f\"📊 **Total Carbon Emission**: {carbon_emission:.2f} kg CO₂ per month\")\n",
    "    \n",
    "    print(\"\\n📌 **Breakdown by Category:**\")\n",
    "    for category, value in carbon_breakdown.items():\n",
    "        print(f\"  - {category.capitalize()}: {value:.2f} kg CO₂\")\n",
    "\n",
    "    # Plot trend analysis\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.bar(carbon_breakdown.keys(), carbon_breakdown.values(), color=['red', 'blue', 'green', 'purple', 'orange'])\n",
    "    plt.xlabel(\"Categories\")\n",
    "    plt.ylabel(\"CO₂ Emissions (kg)\")\n",
    "    plt.title(\"Carbon Footprint Breakdown\")\n",
    "    plt.show()\n",
    "\n",
    "    # Print AI-powered reduction strategies\n",
    "    print(\"\\n✅ **AI-Powered Reduction Strategies**\")\n",
    "    for category, _ in sorted_categories[:2]:  \n",
    "        print(f\"➡️ {reduction_tips[category]}\")\n",
    "\n",
    "# Run function to take input and generate report\n",
    "generate_carbon_report()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b3f7751f-4148-4e0b-b338-f0d7085b3314",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Save the trained neural network model\n",
    "model.save(\"carbon_footprint_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4dd7f881-3fe3-42fe-9e6e-0522b45d1c73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler.pkl']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the encoder\n",
    "joblib.dump(encoder, \"encoder.pkl\")\n",
    "\n",
    "# Save the scaler\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dcbb251e-d008-458e-b3aa-38037ba40603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔄 Training the model...\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adity\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 4377044480.0000 - mae: 57797.1602 - val_loss: 3930184704.0000 - val_mae: 53654.4141\n",
      "Epoch 2/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4603929088.0000 - mae: 59111.9766 - val_loss: 3912897280.0000 - val_mae: 53511.0039\n",
      "Epoch 3/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4494762496.0000 - mae: 58459.2188 - val_loss: 3851083776.0000 - val_mae: 53005.1641\n",
      "Epoch 4/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4273281280.0000 - mae: 56013.1172 - val_loss: 3719134464.0000 - val_mae: 51912.8359\n",
      "Epoch 5/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4178272000.0000 - mae: 55205.0039 - val_loss: 3502995968.0000 - val_mae: 50086.5547\n",
      "Epoch 6/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3641713920.0000 - mae: 50919.8398 - val_loss: 3199550464.0000 - val_mae: 47466.4844\n",
      "Epoch 7/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3368952576.0000 - mae: 48947.9375 - val_loss: 2821263104.0000 - val_mae: 44133.0664\n",
      "Epoch 8/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3091742208.0000 - mae: 47315.9023 - val_loss: 2382290944.0000 - val_mae: 40052.5664\n",
      "Epoch 9/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2519178496.0000 - mae: 41191.0898 - val_loss: 1931721472.0000 - val_mae: 35621.8633\n",
      "Epoch 10/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2012368256.0000 - mae: 36619.0781 - val_loss: 1494139392.0000 - val_mae: 30953.8633\n",
      "Epoch 11/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1468694144.0000 - mae: 30836.6641 - val_loss: 1101936512.0000 - val_mae: 26349.9082\n",
      "Epoch 12/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1137867264.0000 - mae: 27187.0059 - val_loss: 785166656.0000 - val_mae: 22346.0332\n",
      "Epoch 13/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 830479488.0000 - mae: 23651.2695 - val_loss: 554083392.0000 - val_mae: 19103.7871\n",
      "Epoch 14/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 579264512.0000 - mae: 19693.4473 - val_loss: 406103616.0000 - val_mae: 16664.2051\n",
      "Epoch 15/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 418384352.0000 - mae: 17262.0293 - val_loss: 314209984.0000 - val_mae: 14953.7246\n",
      "Epoch 16/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 331796992.0000 - mae: 15447.0098 - val_loss: 259178560.0000 - val_mae: 13791.5088\n",
      "Epoch 17/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 256960864.0000 - mae: 13856.1182 - val_loss: 223906736.0000 - val_mae: 12892.9297\n",
      "Epoch 18/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 221785264.0000 - mae: 12830.3525 - val_loss: 196966320.0000 - val_mae: 12115.0820\n",
      "Epoch 19/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 197695376.0000 - mae: 12048.2920 - val_loss: 173998096.0000 - val_mae: 11393.6592\n",
      "Epoch 20/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 171025568.0000 - mae: 11247.3799 - val_loss: 152983792.0000 - val_mae: 10680.1113\n",
      "Epoch 21/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 149098112.0000 - mae: 10506.3760 - val_loss: 133480552.0000 - val_mae: 9969.6074\n",
      "Epoch 22/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 125663440.0000 - mae: 9692.3594 - val_loss: 115731568.0000 - val_mae: 9272.1035\n",
      "Epoch 23/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 109473672.0000 - mae: 8977.4023 - val_loss: 99186752.0000 - val_mae: 8575.4531\n",
      "Epoch 24/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 94203512.0000 - mae: 8350.6787 - val_loss: 84009384.0000 - val_mae: 7882.8052\n",
      "Epoch 25/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 71455184.0000 - mae: 7162.8311 - val_loss: 70832112.0000 - val_mae: 7226.8950\n",
      "Epoch 26/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 65112748.0000 - mae: 6856.0391 - val_loss: 58411624.0000 - val_mae: 6555.6748\n",
      "Epoch 27/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57268216.0000 - mae: 6449.4673 - val_loss: 47868840.0000 - val_mae: 5924.3276\n",
      "Epoch 28/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 43962840.0000 - mae: 5627.4150 - val_loss: 38772632.0000 - val_mae: 5325.7695\n",
      "Epoch 29/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 36450372.0000 - mae: 5184.9868 - val_loss: 30840304.0000 - val_mae: 4743.1177\n",
      "Epoch 30/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28652050.0000 - mae: 4602.3916 - val_loss: 24152912.0000 - val_mae: 4187.7891\n",
      "Epoch 31/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 22349464.0000 - mae: 4040.6509 - val_loss: 18597304.0000 - val_mae: 3668.8018\n",
      "Epoch 32/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17032884.0000 - mae: 3531.1365 - val_loss: 14196131.0000 - val_mae: 3196.3347\n",
      "Epoch 33/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13352119.0000 - mae: 3108.9897 - val_loss: 10552612.0000 - val_mae: 2742.1045\n",
      "Epoch 34/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9566901.0000 - mae: 2634.0081 - val_loss: 7743344.0000 - val_mae: 2339.2109\n",
      "Epoch 35/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7529544.5000 - mae: 2331.3384 - val_loss: 5607923.0000 - val_mae: 1979.0161\n",
      "Epoch 36/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5140300.5000 - mae: 1911.9551 - val_loss: 4011103.0000 - val_mae: 1662.8821\n",
      "Epoch 37/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3519338.0000 - mae: 1573.9106 - val_loss: 2803363.2500 - val_mae: 1378.0863\n",
      "Epoch 38/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2533736.5000 - mae: 1335.8685 - val_loss: 1943222.7500 - val_mae: 1132.4296\n",
      "Epoch 39/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1723817.8750 - mae: 1080.6901 - val_loss: 1345476.5000 - val_mae: 926.2504\n",
      "Epoch 40/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1229570.8750 - mae: 906.7768 - val_loss: 919858.6250 - val_mae: 748.3731\n",
      "Epoch 41/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 753109.6250 - mae: 697.4058 - val_loss: 635053.3125 - val_mae: 603.1201\n",
      "Epoch 42/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 502303.7812 - mae: 551.8780 - val_loss: 447347.8438 - val_mae: 484.9628\n",
      "Epoch 43/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 337443.1562 - mae: 448.0800 - val_loss: 318991.9062 - val_mae: 386.6243\n",
      "Epoch 44/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 249228.8125 - mae: 351.8285 - val_loss: 236773.3750 - val_mae: 310.5127\n",
      "Epoch 45/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 152628.8906 - mae: 272.5639 - val_loss: 183534.0781 - val_mae: 252.6158\n",
      "Epoch 46/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 127185.7500 - mae: 223.7350 - val_loss: 148340.5781 - val_mae: 209.2495\n",
      "Epoch 47/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 80965.9297 - mae: 163.1946 - val_loss: 127564.1719 - val_mae: 181.7714\n",
      "Epoch 48/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 102107.5391 - mae: 153.6115 - val_loss: 114200.1562 - val_mae: 160.7980\n",
      "Epoch 49/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 81043.6328 - mae: 135.9086 - val_loss: 105365.2891 - val_mae: 146.2205\n",
      "Epoch 50/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 72596.1406 - mae: 112.5958 - val_loss: 99251.1797 - val_mae: 138.1321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Model training complete! Now you can enter new data to predict emissions.\n",
      "\n",
      "📌 Enter company details to predict CO₂ emissions:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Industry Sector ['Mining', 'Service', 'Manufacturing', 'Agriculture', 'Retail']:  mining\n",
      "Location ['Cape Town, South Africa', 'Cairo, Egypt', 'Accra, Ghana', 'Nairobi, Kenya', 'Lagos, Nigeria']:  'Cairo, Egypt'\n",
      "Raw Material ['Steel', 'Aluminum', 'Copper']:  steel\n",
      "Number of Employees:  50\n",
      "Annual Electricity Usage (kWh):  4567\n",
      "Annual Fuel Consumption (liters):  345\n",
      "Percentage of Renewable Energy Used (%):  80\n",
      "Raw Material Quantity (tons):  45\n",
      "Total Annual Waste Generated:  45\n",
      "Percentage of Waste Recycled:  80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\n",
      "🌍 Predicted CO₂ Emissions: 77.43 metric tons\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load dataset\n",
    "dataset_path = \"C:/Users/adity/Downloads/sme_carbon_footprint_data.csv\"  # Update this with your file path\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Define categorical and numerical features\n",
    "categorical_features = [\"Industry Sector\", \"Location\", \"Raw Material\"]\n",
    "numerical_features = [\n",
    "    \"Number of Employees\", \"Annual Electricity Usage (kWh)\", \"Annual Fuel Consumption (liters)\",\n",
    "    \"Percentage of Renewable Energy Used (%)\", \"Raw Material Quantity (tons)\",\n",
    "    \"Total Annual Waste Generated (tons)\", \"Percentage of Waste Recycled (%)\"\n",
    "]\n",
    "\n",
    "target_column = \"Total Annual CO2 Emissions (metric tons)\"\n",
    "\n",
    "# Encode categorical variables\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
    "encoded_categorical = encoder.fit_transform(df[categorical_features])\n",
    "encoded_categorical_df = pd.DataFrame(encoded_categorical, columns=encoder.get_feature_names_out())\n",
    "\n",
    "# Scale numerical variables\n",
    "scaler = StandardScaler()\n",
    "scaled_numerical = scaler.fit_transform(df[numerical_features])\n",
    "scaled_numerical_df = pd.DataFrame(scaled_numerical, columns=numerical_features)\n",
    "\n",
    "# Merge processed features\n",
    "X = pd.concat([encoded_categorical_df, scaled_numerical_df], axis=1)\n",
    "y = df[target_column]\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the Neural Network model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Train the model\n",
    "print(\"\\n🔄 Training the model...\")\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=8, validation_data=(X_test, y_test), verbose=1)\n",
    "\n",
    "# Save the trained model and encoders\n",
    "model.save(\"carbon_emission_model1.h5\")\n",
    "joblib.dump(encoder, \"encoder1.pkl\")\n",
    "joblib.dump(scaler, \"scaler1.pkl\")\n",
    "\n",
    "print(\"\\n✅ Model training complete! Now you can enter new data to predict emissions.\")\n",
    "\n",
    "# Function to predict emissions from user input\n",
    "def predict_emissions():\n",
    "    print(\"\\n📌 Enter company details to predict CO₂ emissions:\")\n",
    "\n",
    "    # User inputs\n",
    "    user_data = {\n",
    "        \"Industry Sector\": input(f\"Industry Sector {df['Industry Sector'].unique().tolist()}: \"),\n",
    "        \"Location\": input(f\"Location {df['Location'].unique().tolist()}: \"),\n",
    "        \"Raw Material\": input(f\"Raw Material {df['Raw Material'].unique().tolist()}: \"),\n",
    "        \"Number of Employees\": float(input(\"Number of Employees: \")),\n",
    "        \"Annual Electricity Usage (kWh)\": float(input(\"Annual Electricity Usage (kWh): \")),\n",
    "        \"Annual Fuel Consumption (liters)\": float(input(\"Annual Fuel Consumption (liters): \")),\n",
    "        \"Percentage of Renewable Energy Used (%)\": float(input(\"Percentage of Renewable Energy Used (%): \")),\n",
    "        \"Raw Material Quantity (tons)\": float(input(\"Raw Material Quantity (tons): \")),\n",
    "        \"Total Annual Waste Generated (tons)\": float(input(\"Total Annual Waste Generated: \")),\n",
    "        \"Percentage of Waste Recycled (%)\": float(input(\"Percentage of Waste Recycled: \"))\n",
    "    }\n",
    "\n",
    "    # Convert input to DataFrame\n",
    "    user_df = pd.DataFrame([user_data])\n",
    "\n",
    "    # Encode categorical variables\n",
    "    encoded_categorical = encoder.transform(user_df[categorical_features])\n",
    "    encoded_categorical_df = pd.DataFrame(encoded_categorical, columns=encoder.get_feature_names_out())\n",
    "\n",
    "    # Scale numerical variables\n",
    "    scaled_numerical = scaler.transform(user_df[numerical_features])\n",
    "    scaled_numerical_df = pd.DataFrame(scaled_numerical, columns=numerical_features)\n",
    "\n",
    "    # Merge processed input\n",
    "    processed_input = pd.concat([encoded_categorical_df, scaled_numerical_df], axis=1)\n",
    "\n",
    "    # 🔄 Load model with compile=False to avoid loss function issue\n",
    "    model = load_model(\"carbon_emission_model1.h5\", compile=False)\n",
    "\n",
    "    # ✅ Manually recompile the model\n",
    "    model.compile(optimizer=\"adam\", loss=\"mean_squared_error\", metrics=[\"mae\"])\n",
    "    prediction = model.predict(processed_input)\n",
    "\n",
    "    print(f\"\\n🌍 Predicted CO₂ Emissions: {prediction[0][0]:.2f} metric tons\")\n",
    "\n",
    "# Run prediction\n",
    "predict_emissions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b56e1a-9065-46a0-9f76-f2ef26fe2419",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
